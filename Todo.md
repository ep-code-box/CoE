### 프로젝트 할 일 목록

**1. CoE 에이전트의 OpenAI API 호환성 확보**
*   **목표:** `coe-agent`가 OpenAI API 사양과 호환되는 API를 제공하도록 수정하여, 더 넓은 통합과 사용 편의성을 확보합니다.
*   **작업:**
    *   에뮬레이션할 특정 OpenAI API 엔드포인트(예: `/v1/chat/completions`)를 식별하고 우선순위를 정합니다. **(완료 - `/v1/chat/completions` 엔드포인트의 에이전트 응답 형식은 OpenAI 호환으로 확인됨)**
    *   기존 `coe-agent` 기능 및 데이터 모델을 OpenAI API 요청 및 응답 스키마에 매핑합니다. **(완료 - 입력(`OpenAIChatRequest`) 및 출력 형식은 OpenAI 호환으로 확인됨)**
    *   들어오는 OpenAI 호환 요청 및 나가는 응답을 변환하기 위해 `coe-agent` 내에 필요한 어댑터, 래퍼 또는 새로운 API 경로를 구현합니다. **(완료 - 기존 구조가 이미 대부분 호환되어 추가 어댑터/래퍼 불필요)**
    *   일반적인 OpenAI API 키 패턴을 지원하도록 인증 메커니즘을 검토하고 조정합니다. **(미완료)**

**2. 채팅 완성(Chat Completions)에서 RAG 기반 검색 우선 처리 (group_name 활용)**
*   **목표:** `chat/completions` 엔드포인트를 개선하여 `group_name`이 제공될 때 RAG(검색 증강 생성) 기반 검색을 우선적으로 처리함으로써, 문맥에 맞는 응답을 보장합니다.
*   **작업:**
    *   `group_name` 매개변수가 채팅 완성 요청과 함께 일관되게 전달되고 처리되는지 확인합니다. **(완료 - `OpenAIChatRequest`에 `group_name` 필드 추가 및 `call_rag_service`로 전달 로직 구현)**
    *   채팅 완성 처리 로직을 수정하여 `group_name`을 감지하고 활용하도록 합니다. **(완료 - `group_name`이 `call_rag_service`로 전달되고 RAG 파이프라인에서 활용됨)**
    *   제공된 `group_name`을 기반으로 검색을 필터링하거나 문맥화하여 RAG 파이프라인을 트리거합니다. **(완료 - `group_name`이 `call_rag_service`를 통해 RAG 파이프라인으로 전달되어 필터링에 활용됨)**
    *   RAG를 통해 검색된 정보를 LLM의 프롬프트에 효과적으로 통합하여 최종 채팅 완성을 생성하는 전략을 개발합니다. **(완료 - RAG 결과가 LLM/에이전트 프롬프트에 컨텍스트로 통합됨)**

**3. 유지보수를 위한 코드 모듈화 및 문서화 개선**
*   **목표:** 코드베이스를 리팩토링하여 모듈성을 강화하고 포괄적인 문서화를 제공함으로써 전반적인 유지보수성과 가독성을 향상시킵니다.
*   **작업:**
    *   높은 결합도, 불분명한 책임 또는 지나치게 복잡한 함수/클래스가 있는 영역을 식별하기 위해 코드 검토를 수행합니다.
    *   식별된 섹션을 더 작고, 더 응집력 있으며, 단일 책임 원칙을 따르는 모듈 또는 구성 요소로 리팩토링합니다.
    *   모든 함수, 메서드, 클래스 및 모듈에 대해 목적, 인수 및 반환 값을 설명하는 포괄적인 독스트링(예: Sphinx 또는 Google 스타일)을 추가합니다.
    *   복잡하거나 명확하지 않은 로직에 대해 의도를 명확히 하기 위해 인라인 주석을 추가합니다.
    *   향후 개발을 안내할 수 있는 상위 수준의 아키텍처 문서 또는 설계 원칙을 생성하거나 업데이트하는 것을 고려합니다.

**4. RAG 파이프라인 성능 및 품질 고도화**
*   **목표:** RAG 파이프라인의 효율성, 정확성 및 관련성을 지속적으로 개선합니다.
*   **작업 (성능):**
    *   현재 RAG 파이프라인의 성능 기준 지표(예: 검색 지연 시간, 처리량, 인덱싱 속도)를 설정합니다.
    *   벡터 저장소 또는 데이터베이스에서 데이터 검색을 위한 최적화를 조사하고 구현합니다.
    *   더 효율적인 임베딩 모델 또는 벡터 데이터베이스 구성을 사용하는 것을 탐색합니다.
    *   자주 액세스하는 RAG 결과 또는 임베딩에 대한 캐싱 메커니즘을 구현합니다.
*   **작업 (품질):**
    *   RAG 품질에 대한 명확한 지표 및 평가 방법론(예: 검색된 문서의 관련성, 생성된 응답의 사실적 정확성, 환각 감소)을 정의합니다.
    *   검색을 최적화하기 위해 다양한 문서 청킹 전략, 오버랩 설정 및 메타데이터 처리를 실험합니다.
    *   다양한 도메인 또는 데이터 유형에서 임베딩 모델의 효과를 평가하고 비교합니다。
    *   RAG 결과를 더 잘 활용하고 통합하기 위해 LLM에 대한 프롬프트 엔지니어링 기술을 개선합니다.
    *   사용자 상호 작용 또는 전문가 검토를 기반으로 RAG 품질을 지속적으로 모니터링하고 개선하기 위한 피드백 루프 메커니즘을 구현합니다。